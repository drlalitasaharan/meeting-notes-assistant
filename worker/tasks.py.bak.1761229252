from __future__ import annotations

import json, logging, os, time
from datetime import datetime
from typing import Optional

from prometheus_client import Counter, Histogram
from sqlalchemy import asc
from sqlalchemy.orm import Session
from app.db import SessionLocal

try:
    from app.core.settings import settings
except Exception:
    import os
    class _Fallback:
        OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
        LLM_MODEL = os.environ.get("LLM_MODEL", "gpt-4o-mini")
    settings = _Fallback()

try:
    from app.models.summary import Summary
    from app.models.transcript import Transcript
except Exception:
    try:
        from app.models import Summary, Transcript
    except Exception:
        class Summary: ...
        class Transcript: ...





# NOTE: absolute imports from the backend app package
try:
except Exception:
    import os
    class _Fallback:
        OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
        LLM_MODEL = os.environ.get("LLM_MODEL", "gpt-4o-mini")
    settings = _Fallback()

except Exception:
    import os
    class _Fallback:
        OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
        LLM_MODEL = os.environ.get("LLM_MODEL", "gpt-4o-mini")
    settings = _Fallback()
from app.services.storage import choose_storage

log = logging.getLogger(__name__)

JOB_COUNT = Counter("job_count_by_status", "Jobs by status", ["job", "status"])
JOB_DURATION = Histogram("job_duration_seconds", "Job duration seconds", ["job"])


# ---------- Helpers ----------
def _put_json(storage, key: str, obj: dict):
    data = json.dumps(obj)
    if hasattr(storage, "put_json"):
        storage.put_json(key, obj); return
    if hasattr(storage, "put"):
        storage.put(key, data.encode(), content_type="application/json"); return
    if hasattr(storage, "client") and hasattr(storage, "bucket"):
        storage.client.put_object(
            Bucket=storage.bucket, Key=key, Body=data, ContentType="application/json"
        ); return
    raise RuntimeError("No supported put method on storage")


# ---------- Job system tasks ----------
def demo_job(job_id: str, job_type: str, payload: dict):
    start = time.time()
    db = SessionLocal()
    job = None
    try:
        job = db.get(Job, job_id)
        if not job:
            return
        job.status = JobStatus.running
        db.commit()

        storage = choose_storage()
        key = f"jobs/{job_id}.json"
        _put_json(storage, key, {"echo": payload, "ok": True})
        job.artifact_key = key

        job.status = JobStatus.succeeded
        db.commit()
        JOB_COUNT.labels("demo_job", "success").inc()
    except Exception as e:
        log.exception("demo_job failed for %s", job_id)
        if job:
            job.status = JobStatus.failed
            job.error = str(e)
            db.commit()
        JOB_COUNT.labels("demo_job", "error").inc()
        raise
    finally:
        JOB_DURATION.labels("demo_job").observe(time.time() - start)
        db.close()


def generic_job(job_id: str, job_type: str, payload: dict):
    start = time.time()
    db = SessionLocal()
    try:
        job = db.get(Job, job_id)
        if job:
            job.status = JobStatus.succeeded
            db.commit()
            JOB_COUNT.labels("generic_job", "success").inc()
    except Exception:
        JOB_COUNT.labels("generic_job", "error").inc()
        raise
    finally:
        JOB_DURATION.labels("generic_job").observe(time.time() - start)
        db.close()


# ---------- Your existing meeting tasks (unchanged except imports) ----------
def ocr_slides(meeting_id: int, slides_dir: Optional[str] = None) -> int:
    import pytesseract
    from PIL import Image

    start = time.time()
    try:
        base = slides_dir or os.path.join("storage", str(meeting_id))
        texts = []
        if not os.path.isdir(base):
            return 0
        for fn in sorted(os.listdir(base)):
            if fn.lower().endswith((".png", ".jpg", ".jpeg", ".bmp", ".tiff")):
                p = os.path.join(base, fn)
                try:
                    img = Image.open(p)
                    txt = pytesseract.image_to_string(img)
                    if txt.strip():
                        texts.append(f"[{fn}]\n{txt.strip()}")
                except Exception:
                    continue
        if not texts:
            return 0
        db: Session = SessionLocal()
        try:
            t = Transcript(meeting_id=meeting_id, source="ocr", text="\n\n".join(texts))
            db.add(t)
            db.commit()
        finally:
            db.close()
        JOB_COUNT.labels("ocr_slides", "success").inc()
        return len(texts)
    except Exception:
        JOB_COUNT.labels("ocr_slides", "error").inc()
        raise
    finally:
        JOB_DURATION.labels("ocr_slides").observe(time.time() - start)


def summarize_meeting(meeting_id: int, max_chars: int = 8000) -> str:
    start = time.time()
    try:
        db: Session = SessionLocal()
        try:
            texts = (
                db.query(Transcript)
                .filter(Transcript.meeting_id == meeting_id)
                .order_by(asc(Transcript.created_at))
                .all()
            )
            corpus = "\n\n".join(t.text for t in texts)[:max_chars]
        finally:
            db.close()

        if not corpus.strip():
            bullets = "- No transcript or OCR text available."
        else:
            if settings.OPENAI_API_KEY:
                from openai import OpenAI
                client = OpenAI(api_key=settings.OPENAI_API_KEY)
                prompt = (
                    "Summarize as 5â€“8 crisp bullets. Include key decisions and action items.\n\n"
                    f"Transcript:\n{corpus}"
                )
                resp = client.chat.completions.create(
                    model=settings.LLM_MODEL,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.2,
                )
                content = resp.choices[0].message.content or ""
                bullets = content.strip()
            else:
                lines = [ln.strip() for ln in corpus.splitlines() if ln.strip()]
                bullets = "\n".join(f"- {ln[:160]}" for ln in lines[:8])

        db = SessionLocal()
        try:
            existing = db.query(Summary).filter(Summary.meeting_id == meeting_id).one_or_none()
            if existing:
                setattr(existing, "bullets", bullets)
                existing.created_at = datetime.utcnow()
            else:
                db.add(Summary(meeting_id=meeting_id, bullets=bullets))
            db.commit()
        finally:
            db.close()

        JOB_COUNT.labels("summarize_meeting", "success").inc()
        return "ok"
    except Exception:
        JOB_COUNT.labels("summarize_meeting", "error").inc()
        raise
    finally:
        JOB_DURATION.labels("summarize_meeting").observe(time.time() - start)
